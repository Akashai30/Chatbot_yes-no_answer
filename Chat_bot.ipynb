{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Bot:\n",
    "* **This model is based on the End-to-End Memory network. This model is trained using babi dataset, published by Facebook research.**\n",
    "* The summary of the data is following:\n",
    "    1. A story of 4-5 sentences is provided to the model.\n",
    "    2. A question is given to the model based on the story given.\n",
    "    3. Answer is binary i.e. yes or no type.\n",
    "* Model summary is as given below:\n",
    "    1. The story is used as the memory.\n",
    "    2. The story is embedded using embedding matrix.\n",
    "    3. Question is matched with the question, which is also embedded with different embedding matrix. **Softmax activation** function is used for scoring the match.\n",
    "    4. Another embedded matrix is also used in the model, this vectorize the story, which is then added with the match matrix.This is called response\n",
    "    5. This inturn, is concatnated with the question (which is embedded) to produce the input for decoder(answer).\n",
    "    6. This is then passed to **LSTM** layer.\n",
    "    7. And then finally connected to a **Dense** layer.\n",
    "    8. This is activated with the **sigmoid** fuction to produe probability of each of the word.\n",
    "    9. Answer will be with highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt', 'rb') as fp:\n",
    "    train_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt', 'rb') as fp:\n",
    "    test_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab  = set()\n",
    "all_data = train_data+test_data\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')\n",
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1\n",
    "story_max_len = max([len(data[0]) for data in all_data])\n",
    "ques_max_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(vocab)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized(data,word_index = word_index, max_story = story_max_len, max_ques = ques_max_len ):\n",
    "    #for the stories(x)\n",
    "    X = []\n",
    "    \n",
    "    #for the question(q)\n",
    "    Xq = []\n",
    "    \n",
    "    #for the answer(a)\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        \n",
    "        #assigning index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        \n",
    "        #assigning index for every word in story\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        # assign index for the answer\n",
    "        \n",
    "        a = np.zeros(len(word_index) + 1)\n",
    "        a[word_index[answer]] =1\n",
    "        \n",
    "        X.append(x)\n",
    "        \n",
    "        Xq.append(xq)\n",
    "        \n",
    "        A.append(a)\n",
    "        \n",
    "        \n",
    "    return (pad_sequences(X, maxlen= max_story), pad_sequences(Xq, maxlen= max_ques), np.array(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story , train_question , train_answer = vectorized(train_data, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_story, test_question, test_answer = vectorized(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Permute, add, concatenate, dot, Activation, Input, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq  = Input((story_max_len,))\n",
    "ques = Input((ques_max_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the encoder as defined in the paper , \"End to End Menory Netowrks\"\n",
    "\n",
    "Encoder M, this is used to store and encode memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_m = Sequential()\n",
    "encoder_m.add(Embedding(input_dim= vocab_len, output_dim = 64))\n",
    "encoder_m.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can encode C encoder, the output_dimension will be equal to the max length of the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_c = Sequential()\n",
    "encoder_c.add(Embedding(input_dim = vocab_len, output_dim = ques_max_len))\n",
    "encoder_c.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a question encoder, which will take question as input vector and provide the embedded vector. Output diemensions would be 64 in this case as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim = vocab_len, output_dim= 64,input_length = ques_max_len ))\n",
    "question_encoder.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = encoder_m(input_seq)\n",
    "input_encoded_c = encoder_c(input_seq)\n",
    "question_encoded = question_encoder(ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/Identity:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_len)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('sigmoid')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_seq, ques], answer)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[1][0]                 \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 9s 901us/sample - loss: 0.1143 - accuracy: 0.9545 - val_loss: 0.0367 - val_accuracy: 0.9737\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0381 - accuracy: 0.9739 - val_loss: 0.0365 - val_accuracy: 0.9738\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0369 - accuracy: 0.9738 - val_loss: 0.0366 - val_accuracy: 0.9735\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0366 - accuracy: 0.9737 - val_loss: 0.0366 - val_accuracy: 0.9738\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 2s 240us/sample - loss: 0.0365 - accuracy: 0.9740 - val_loss: 0.0365 - val_accuracy: 0.9738\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.97 - 2s 236us/sample - loss: 0.0365 - accuracy: 0.9735 - val_loss: 0.0365 - val_accuracy: 0.9738\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0365 - accuracy: 0.9739 - val_loss: 0.0365 - val_accuracy: 0.9738\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0365 - accuracy: 0.9737 - val_loss: 0.0365 - val_accuracy: 0.9738\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.0365 - accuracy: 0.9741 - val_loss: 0.0365 - val_accuracy: 0.9733\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0365 - accuracy: 0.9737 - val_loss: 0.0365 - val_accuracy: 0.9735\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0365 - accuracy: 0.9738 - val_loss: 0.0365 - val_accuracy: 0.9738\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0365 - accuracy: 0.9738 - val_loss: 0.0365 - val_accuracy: 0.9735\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.97 - 2s 232us/sample - loss: 0.0365 - accuracy: 0.9740 - val_loss: 0.0365 - val_accuracy: 0.9726\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0365 - accuracy: 0.9742 - val_loss: 0.0365 - val_accuracy: 0.9728\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 2s 241us/sample - loss: 0.0364 - accuracy: 0.9749 - val_loss: 0.0366 - val_accuracy: 0.9726\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 3s 266us/sample - loss: 0.0363 - accuracy: 0.9751 - val_loss: 0.0364 - val_accuracy: 0.9760\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0360 - accuracy: 0.9767 - val_loss: 0.0361 - val_accuracy: 0.9767\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 2s 245us/sample - loss: 0.0351 - accuracy: 0.9788 - val_loss: 0.0345 - val_accuracy: 0.9800\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0336 - accuracy: 0.9816 - val_loss: 0.0331 - val_accuracy: 0.9818\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.98 - 2s 227us/sample - loss: 0.0323 - accuracy: 0.9828 - val_loss: 0.0316 - val_accuracy: 0.9840\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 2s 236us/sample - loss: 0.0310 - accuracy: 0.9841 - val_loss: 0.0300 - val_accuracy: 0.9851\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0291 - accuracy: 0.9858 - val_loss: 0.0274 - val_accuracy: 0.9874\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 2s 248us/sample - loss: 0.0278 - accuracy: 0.9870 - val_loss: 0.0262 - val_accuracy: 0.9881\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.0269 - accuracy: 0.9873 - val_loss: 0.0258 - val_accuracy: 0.9882\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.0254 - accuracy: 0.9884 - val_loss: 0.0252 - val_accuracy: 0.9887\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0247 - accuracy: 0.9887 - val_loss: 0.0248 - val_accuracy: 0.9894\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0237 - accuracy: 0.9895 - val_loss: 0.0244 - val_accuracy: 0.9895\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0225 - accuracy: 0.9902 - val_loss: 0.0236 - val_accuracy: 0.9900\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0217 - accuracy: 0.9910 - val_loss: 0.0222 - val_accuracy: 0.9905\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.0218 - val_accuracy: 0.9912\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0207 - accuracy: 0.9913 - val_loss: 0.0218 - val_accuracy: 0.9911\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0199 - accuracy: 0.9918 - val_loss: 0.0216 - val_accuracy: 0.9909\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 2s 246us/sample - loss: 0.0196 - accuracy: 0.9921 - val_loss: 0.0225 - val_accuracy: 0.9908\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0195 - accuracy: 0.9919 - val_loss: 0.0219 - val_accuracy: 0.9911\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 2s 235us/sample - loss: 0.0188 - accuracy: 0.9923 - val_loss: 0.0211 - val_accuracy: 0.9906\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0187 - accuracy: 0.9924 - val_loss: 0.0211 - val_accuracy: 0.9910\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0184 - accuracy: 0.9924 - val_loss: 0.0208 - val_accuracy: 0.9908\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0183 - accuracy: 0.9926 - val_loss: 0.0207 - val_accuracy: 0.9906\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0180 - accuracy: 0.9925 - val_loss: 0.0209 - val_accuracy: 0.9913\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0179 - accuracy: 0.9926 - val_loss: 0.0210 - val_accuracy: 0.9909\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0178 - accuracy: 0.9926 - val_loss: 0.0203 - val_accuracy: 0.9912\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0172 - accuracy: 0.9927 - val_loss: 0.0201 - val_accuracy: 0.9909\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0172 - accuracy: 0.9928 - val_loss: 0.0206 - val_accuracy: 0.9909\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0171 - accuracy: 0.9929 - val_loss: 0.0204 - val_accuracy: 0.9914\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0167 - accuracy: 0.9930 - val_loss: 0.0210 - val_accuracy: 0.9908\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0167 - accuracy: 0.9928 - val_loss: 0.0203 - val_accuracy: 0.9910\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0165 - accuracy: 0.9933 - val_loss: 0.0206 - val_accuracy: 0.9911\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0165 - accuracy: 0.9930 - val_loss: 0.0206 - val_accuracy: 0.9916\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 2s 238us/sample - loss: 0.0164 - accuracy: 0.9931 - val_loss: 0.0220 - val_accuracy: 0.9913\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0162 - accuracy: 0.9931 - val_loss: 0.0204 - val_accuracy: 0.9912\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 2s 235us/sample - loss: 0.0160 - accuracy: 0.9933 - val_loss: 0.0205 - val_accuracy: 0.9914\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0158 - accuracy: 0.9934 - val_loss: 0.0216 - val_accuracy: 0.9913\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0155 - accuracy: 0.9933 - val_loss: 0.0214 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 2s 225us/sample - loss: 0.0155 - accuracy: 0.9936 - val_loss: 0.0199 - val_accuracy: 0.9911\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.0154 - accuracy: 0.9936 - val_loss: 0.0210 - val_accuracy: 0.9907\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.0153 - accuracy: 0.9934 - val_loss: 0.0209 - val_accuracy: 0.9909\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.0211 - val_accuracy: 0.9915\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0152 - accuracy: 0.9935 - val_loss: 0.0206 - val_accuracy: 0.9914\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0151 - accuracy: 0.9936 - val_loss: 0.0208 - val_accuracy: 0.9906\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.0211 - val_accuracy: 0.9914\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.0146 - accuracy: 0.9938 - val_loss: 0.0202 - val_accuracy: 0.9909\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0144 - accuracy: 0.9939 - val_loss: 0.0200 - val_accuracy: 0.9915\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0145 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9912\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0145 - accuracy: 0.9940 - val_loss: 0.0223 - val_accuracy: 0.9913\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0140 - accuracy: 0.9943 - val_loss: 0.0220 - val_accuracy: 0.9912\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 2s 248us/sample - loss: 0.0142 - accuracy: 0.9940 - val_loss: 0.0212 - val_accuracy: 0.9910\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.0140 - accuracy: 0.9941 - val_loss: 0.0211 - val_accuracy: 0.9914\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 2s 245us/sample - loss: 0.0138 - accuracy: 0.9943 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0136 - accuracy: 0.9943 - val_loss: 0.0221 - val_accuracy: 0.9913\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0136 - accuracy: 0.9943 - val_loss: 0.0219 - val_accuracy: 0.9913\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.0136 - accuracy: 0.9943 - val_loss: 0.0227 - val_accuracy: 0.9910\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0134 - accuracy: 0.9943 - val_loss: 0.0229 - val_accuracy: 0.9912\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 2s 243us/sample - loss: 0.0132 - accuracy: 0.9944 - val_loss: 0.0220 - val_accuracy: 0.9914\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 3s 255us/sample - loss: 0.0132 - accuracy: 0.9945 - val_loss: 0.0233 - val_accuracy: 0.9917\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 2s 244us/sample - loss: 0.0129 - accuracy: 0.9946 - val_loss: 0.0233 - val_accuracy: 0.9915\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 2s 235us/sample - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.0230 - val_accuracy: 0.9911\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 2s 240us/sample - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.0231 - val_accuracy: 0.9905\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 2s 241us/sample - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.0231 - val_accuracy: 0.9916\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 2s 236us/sample - loss: 0.0126 - accuracy: 0.9946 - val_loss: 0.0231 - val_accuracy: 0.9909\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0124 - accuracy: 0.9948 - val_loss: 0.0259 - val_accuracy: 0.9913\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0243 - val_accuracy: 0.9907\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.0251 - val_accuracy: 0.9908\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0252 - val_accuracy: 0.9909\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0116 - accuracy: 0.9952 - val_loss: 0.0253 - val_accuracy: 0.9912\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.0256 - val_accuracy: 0.9911\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0118 - accuracy: 0.9949 - val_loss: 0.0241 - val_accuracy: 0.9909\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.0259 - val_accuracy: 0.9908\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.0267 - val_accuracy: 0.9903\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0113 - accuracy: 0.9952 - val_loss: 0.0257 - val_accuracy: 0.9907\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0111 - accuracy: 0.9955 - val_loss: 0.0278 - val_accuracy: 0.9906\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0267 - val_accuracy: 0.9908\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0111 - accuracy: 0.9955 - val_loss: 0.0272 - val_accuracy: 0.9906\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 2s 236us/sample - loss: 0.0108 - accuracy: 0.9954 - val_loss: 0.0292 - val_accuracy: 0.9904\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.0287 - val_accuracy: 0.9909\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.0282 - val_accuracy: 0.9903\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0106 - accuracy: 0.9956 - val_loss: 0.0269 - val_accuracy: 0.9909\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0106 - accuracy: 0.9955 - val_loss: 0.0278 - val_accuracy: 0.9908\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 2s 235us/sample - loss: 0.0106 - accuracy: 0.9955 - val_loss: 0.0289 - val_accuracy: 0.9903\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 2s 235us/sample - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.0284 - val_accuracy: 0.9901\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.0299 - val_accuracy: 0.9908\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.0296 - val_accuracy: 0.9901\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.0301 - val_accuracy: 0.9895\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0100 - accuracy: 0.9960 - val_loss: 0.0318 - val_accuracy: 0.9907\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.0307 - val_accuracy: 0.9903\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.0312 - val_accuracy: 0.9908\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0098 - accuracy: 0.9959 - val_loss: 0.0329 - val_accuracy: 0.9908\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 2s 235us/sample - loss: 0.0095 - accuracy: 0.9961 - val_loss: 0.0313 - val_accuracy: 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0097 - accuracy: 0.9961 - val_loss: 0.0303 - val_accuracy: 0.9907\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0097 - accuracy: 0.9959 - val_loss: 0.0324 - val_accuracy: 0.9903\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0097 - accuracy: 0.9959 - val_loss: 0.0326 - val_accuracy: 0.9901\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0095 - accuracy: 0.9961 - val_loss: 0.0340 - val_accuracy: 0.9907\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0094 - accuracy: 0.9961 - val_loss: 0.0346 - val_accuracy: 0.9908\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0092 - accuracy: 0.9962 - val_loss: 0.0333 - val_accuracy: 0.9904\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.0338 - val_accuracy: 0.9902\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0094 - accuracy: 0.9960 - val_loss: 0.0337 - val_accuracy: 0.9903\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.0363 - val_accuracy: 0.9904\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0092 - accuracy: 0.9961 - val_loss: 0.0357 - val_accuracy: 0.9900\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.0353 - val_accuracy: 0.9903\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.0337 - val_accuracy: 0.9901\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.0088 - accuracy: 0.9964 - val_loss: 0.0346 - val_accuracy: 0.9902\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_story, train_question], train_answer,batch_size=32,epochs=120,validation_data=([test_story, test_question], test_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19db6cb4488>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatbot_akash.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_res = model.predict([test_story, test_question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Daniel went back to the kitchen . Mary grabbed the apple there .'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see a test story:\n",
    "\n",
    "' '.join(test_data[5][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Daniel in the office ?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the question asked:\n",
    "\n",
    "' '.join(test_data[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what is the actual answer\n",
    "\n",
    "test_data[5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99993086\n"
     ]
    }
   ],
   "source": [
    "val_max = np.argmax(test_pred_res[5])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "        \n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", test_pred_res[5][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
